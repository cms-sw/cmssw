$Id: README,v 1.16 2007/10/22 21:23:40 narsky Exp $
 
General description of the package:
-----------------------------------

Author:  Ilya Narsky narsky@hep.caltech.edu

Web page: http://www.hep.caltech.edu/~narsky/spr.html


List of all classifiers currently implemented in the package:
------------------------------------------------------------

- decision split (or stump)
- decision tree (2 flavors)
- bump hunter (PRIM)
- LDA and QDA
- logistic regression
- boosting (discrete and real AdaBoost, epsilon-Boost)
- bagging
- random forest
- arc-x4
- backprop neural net with a logistic activation function 
    (original implementation)
- combiner (mixture of experts)
- interfaces to two SNNS neural nets (without training): 
    * backprop neural net with a logistic activation function 
    * RBF


Release notes
-------------

02.04.2007 Tag V05-00-00 introduces a new interface for reading saved
classifier configurations from files. This required multiple changes
to the format. This change is backwards-incompatible. The user won't
be able to read from configuration files produced prior to this tag.
All classifiers need to be re-trained and saved into files again. See
README for a detaied description of the new syntax and new package
features that became possible due to the introduction of the unified
classifier configuration format.

10.14.2006 Due to addition of Real and Epsilon AdaBoosts, the output
format for AdaBoost configuration files has changed. If the user wants
to read configuration files created by releases prior to V03-05-00
with a post-V03-05-00 package release, s/he needs to add the following
line to the configuration file:

Mode: 1

This must be included as a 2nd line in the file, right after the
"Trained AdaBoost:" line. To keep the code clean and maintainable in
the future, I decided not to implement the backwards compatibility in
the code.

Also, the default output in the range [0,1] from AdaBoost has
changed. It is now computed as raw AdaBoost output and then
transformed to [0,1] using 1/(1+exp(-2X)). This directly returns the
probability of an event at X being signal. The earlier algorithm used
before V03-05-00 produced more smooth distributions between 0 and 1;
the new distributions are more peaking near 0 and 1.

09.07.2006 From now on SPR will be released as a standalone package.

06.29.2006 If you are running on not too big data samples in not too
many dimensions, try SprInteractiveAnalysisApp first. It lets you
quickly compare various classifiers.

01.18.2006 Tag V03-00-00 introduces a more flexible treatment of input
classes which allows arbitrary grouping. See Section 5 of this file
and SprAbsFilter.hh for details.

11.12.2005 Starting with tag V01-18-00, the default options for the
two main executables, SprBaggerDecisionTreeApp and
SprAdaBoostDecisionTreeApp, have been reversed. Now by default the two
executables use topdown trees (SprTopdownTree) instead of regular
decision trees (SprDecisionTree) due to their faster performance. The
bagger executable also by default invokes continuous tree output
instead of discrete output. To obtain the old behavior, use "-j"
option for SprAdaBoostDecisionTreeApp and both "-j" and "-k" for
SprBaggerDecisionTreeApp. Users won't be able to read from old
classifier configuration files unless "-j" option is used.

09.11.2005 Tag V01-00-00 introduced a new format for configuration files
used to store boosted and bagged decision trees. The new
SprAdaBoostDecisionTreeApp and SprBaggerDecisionTreeApp will not be
able to read from old configuration files.

Contents
--------
1.  Documentation
2.  Classifiers
	2.1  Boosting
	2.2  Bagging
	2.3  Decision trees
	2.4  Top-down trees
	2.5  Bump hunting
	2.6  Fisher and logistic regression
	2.7  Neural networks
	2.8  Combining classifiers
	2.9  Recommendations: What classifiers to use and when
	2.10 How to choose parameters for boosted and bagged decision trees
	2.11 Cross-validation
	2.12 Multi class learning
3.  Data and filters
4.  Imposing cuts
5.  Treatment of input classes
6.  Estimation of variable importance
7.  Handling input variables
8.  Formats for data input and output
9.  Computing output for trained classifiers
10. Installation instructions
11. How to use trained classifiers in your C++ code
12. Working in Root-free environment
13. Working in Root environment
14. Summary


1. Documentation 
---------------- 

The math formalism behind implemented classifiers, as well as
idealistic and practical examples, can be found in two physics archive
notes:

physics/0507143 "StatPatternRecognition: A C++ Package for Statistical
Analysis of High Energy Physics Data"

physics/0507157 "Optimization of Signal Significance by Bagging
Decision Trees"

The first 4 references in physics/0507143 give a list of introductory
books on pattern classification. Although familiarity with the
material discussed in the books is not necessary to be able to use
this package, I recommend them to every physicist.

One might also want to check out the SLUO lectures on Machine
Learning:
http://www-group.slac.stanford.edu/sluo/Lectures/Stat2006_Lectures.html

The full set of links to papers and talks on StatPatternRecognition
can be found on the web page,
http://www.hep.caltech.edu/~narsky/spr.html .

My talk at the workshop at the BaBar Collaboration Meeting in December
2005 has useful tips for running the package:
http://www.hep.caltech.edu/~narsky/SPR/SPR_Workshop_Dec2005.pdf . Some
of this info may be outdated as the package has gone through
development cycles since then.


2. Classifiers and classes
--------------------------

There are two types of classifiers in the package: trained and trainable.

All trainable classifiers inherit from SprAbsClassifier. The major
method in this class is train(). The purpose of every trainable
classifier is to optimize certain parameters for efficient
signal-background separation. After training has been performed, a
trainable classifier invokes makeTrained() method to produce a
corresponding trained classifier. A trained classifier inherits from
SprAbsTrainedClassifier. The purpose of this class is to produce a
numeric outcome for a data point to classify it using response()
method.

At the moment the following trainable classifiers have been
implemented with corresponding trained counterparts:

- linear and quadratic discriminant analysis (SprFisher)
- a simple binary split in a chosen dimension (SprBinarySplit)
- boosting algorithms (SprAdaBoost): Discrete AdaBoost, Real AdaBoost 
    and epsilon-Boost
- bagging and random forest algorithm (SprBagger)
- arc-x4, yet another boosting algorithm (SprArcE4)
- decision tree with a user-supplied optimization criterion (SprDecisionTree)
- bump hunter (PRIM) with a user-supplied optimization criterion 
    (SprBumpHunter)
- feedforward backpropagation neural net with logistic activation function
    (SprStdBackprop)
- multi-class learner (SprMultiClassLearner)

At present most implemented classifiers deal only with two
categories. The exception is a multi-class learner (see section
2.13). The default class assignment is 0 for background and 1 for
signal. This choice, 0 and 1, is assumed throughout the package. The
user can choose any other pair of classes or group classes in any two
subsets using syntax described in Section 5 and SprAbsFilter.hh.

The output of all implemented classifiers also by default ranges from
0 to 1. If you want to impose a naive cut that crudely chooses
signal-like events over background-like events, you can simply cut at
0.5 on the classifier output. To impose a cut on the classifier
output, use SprAbsTrainedClassifier::setCut() method. accept() method
of every trained classifier returns true if the output of the
classifier satistfies the imposed cut and false otherwise. For all
trained classifiers the cut on the output is by default set at
0.5. The exception are 3 classifiers that can optionally change their
output range from [0,1] to (-infty,+infty); these are AdaBoost, Fisher
and LogitR. useStandard() method sets the range to (-infty,+infty) and
useNormalized() sets it to [0,1]. It is up to the user to set the
output cut for these classifiers to make accept() method work
properly.

The package also offers a set of transformations included in
SprTransformation.hh for converting the classifier output to a
desirable range. For example, to transform the conventional output of
AdaBoost ranging from -infty to +infty to [0,1], logitDouble()
transformation is applied.

The Fisher discriminant represents the log-ratio of two likelihoods at
a given point and includes all appropriate constant terms (often
omitted by people who only care about the Fisher coefficients). By
default the Fisher output is normalized in such a way that positive
values correspond to signal-like events and negative values correspond
to background-like events. The output can range anywhere from -infty
to +infty.

SprTrainedBinarySplit produces a binary response, that is, 0 for
background-like and 1 for signal-like events. The same holds for the
bump hunter. Decision trees can return either discrete or continuous
values depending on the chosen configuration. The response of
SprTrainedAdaBoost is given by a sum of either binary (0 or 1) or
continuous (from -infty to +infty) responses of individual classifiers
multiplied by corresponding beta coefficients (see below section on
AdaBoost).  The response of SprTrainedBagger is given by an algebraic
sum of either binary (0 or 1) or continuous (from 0 to 1) responses of
individual classifiers divided by the total number of individual
classifiers. For a large number of individual classifiers, the output
of SprTrainedAdaBoost and SprTrainedBagger looks practically
continuous, even if each classifier returns discrete output.

Classifiers implemented in the package are described below in more
detail.


2.1 AdaBoost
------------

AdaBoost combines individual classifiers by applying them
consecutively. First AdaBoost reweights events to enhance weights of
those that were misclassified by the last applied subclassifier and to
reduce weights of events that were correctly classified by the last
subclassifier. Then AdaBoost applies a new subclassifier to the
reweighted events.

SprAdaBoost currently implements 3 different algorithms: Discrete
AdaBoost, Real AdaBoost and epsilon-Boost. Specifics of event
reweighting and computing the relative importance (beta coefficients)
for the individual weak classifiers vary.

The implementation of AdaBoost in StatPatternRecognition can combine
any classifiers that inherit from SprAbs(Trained)Classifier. The user
can supply any combination of trained and trainable
classifiers. AdaBoost goes through supplied trained classifiers first
and calculates beta weights for those. These trained classifiers are
not included in the number of training cycles; AdaBoost will always go
through all trained classifiers supplied by the user, no matter how
many training cycles have been requested (the special case is n=0
training cycles which is discussed below). After AdaBoost went through
all trained classifiers, it goes through trainable
classifiers. AdaBoost first trains each trainable classifier on the
reweighted sample, makes a corresponding trained classifier and stores
it in the final list of trained classifiers. AdaBoost goes through
trainable classifiers consecutively in the order in which they were
added to AdaBoost by the user and stops either when the
misclassification fraction reaches 0.5 or when the number of
iterations through trainable classifiers reaches the number of
training cycles requested by the user. For example, if the user
supplies 2 trained and 3 trainable classifiers to AdaBoost and
requests 10 training cycles, AdaBoost will first go through the two
trained classifiers, then go through all 3 trainable classifiers 3
times consecutively (9 training cycles), then do one more training
cycle for the 1st trainable classifier and exit. In this example,
AdaBoost will produce a list of 12 trained classifiers with
corresponding beta weights.

Currently 4 AdaBoost executables are implemented:

SprBoosterApp              - for boosting an arbitrary sequence of classifiers
				 in the package

SprAdaBoostBinarySplitApp  - AdaBoost with binary splits in each dimension

SprAdaBoostDecisionTreeApp - AdaBoost with decision trees

SprStdBackpropApp          - AdaBoost with neural nets

SprBoosterApp has been introduced in tag V05-00-00. In principle,
SprBoosterApp alone should statisfy the needs of a regular user. It is
capable of boosting any sequence of classifiers implemented in the
package. It takes an input file with descriptions of weak classifier
configurations. Use booster.config as a sample. SprBoosterApp
reproduces, to a large extent, the functionality of the 3 other
executables. It offers even more flexibility as the user can combine
any weak classifiers in any sequence. For example, if you put a
decision tree on the first line of the input config line and a neural
net on the second line, AdaBoost will use the decision tree for odd
boosting cycles and the neural net for even boosting cycles.

The other 3 executables will be kept in the package. They offer some
features that SprBoosterApp doesn't; for example, cross-validation or
saving intermediate training weights. Also, for historical reasons -
people who have been using the package for a while may have got used
to the syntax.

Use "-M" option of the executable to choose among available boosting
algorithms (default=Discrete AdaBoost). At the moment, 3 flavors of
boosting are implemented: Discrete, Real and Epsilon. For description,
please refer to the statistics literature.  Discrete AdaBoost and
epsilon-Boost can be used with any weak classifier. Real AdaBoost
requires that the output of the supplied weak learner be continuous
and range from 0 to 1. It is the user's responsibility to use Real
AdaBoost with acceptable weak classifiers.  setEpsilon() method of the
AdaBoost implementation (-E command-line option for the executable)
sets the epsilon value. This value is of no relevance for Discrete
AdaBoost but affects Real and Epsilon algorithms. The meaning of
epsilon is different for Real and Epsilon boosting. For the Epsilon
boost, epsilon defines the rate at which weights are updated for
misclassified events, specifically exp(2*epsilon). For the Real boost,
epsilon defines the margin of the weak classifier response. The
response of each weak classifier, p, for Real boosting must range from
0 to 1 and represent the probablity of an event at this point being
signal. Weights of events are then multiplied by p/(1-p) for
background and (1-p)/p for signal. For p=0 or p=1, the updated weight
goes to infinity. epsilon defines the minimal and (1-epsilon) defines
the maximal allowed value of p to avoid infinite weights. Increasing
epsilon improves stability of the Real boost but may require more
training cycles. It is the other way around for the Epsilon boost -
decreasing epsilon improves stabilty and results in more training
cycles.

When you train AdaBoost on multidimensional data (e.g., hundreds of
dimensions) and large data sets, you will likely need to save an
intermediate AdaBoost configuration to a file and then resume training
later. The AdaBoost configuration file keeps only parameters of the
trained classifiers but not the event weights adjusted due to AdaBoost
application. Your resume job can therefore spend a significant amount
of time reweighting events by applying the trained classifiers from
the saved configuration. To reduce the amount of time spent on initial
reweighting, one can store training data with updated weights into a
new data file at the end of the training routine and then read the
training data with already adjusted weights from this file before
resuming. For example:

SprAdaBoostDecisionTreeApp -a 1 -n 50 -M 1 -l 2000 -f tree_n50.spr -u reweighted_gauss2_uniform_2d_train.pat gauss2_uniform_2d_train.pat

And then:

SprAdaBoostDecisionTreeApp -a 4 -M 1 -n 50 -l 2000 -r tree_n50.spr -f tree_n100.spr -e reweighted_gauss2_uniform_2d_train.pat 

The "-e" option will force AdaBoost to skip the event reweighting;
this option is necessary because events in
reweighted_gauss2_uniform_2d_train.pat have been reweighted
already. The final AdaBoost configuration stored in tree_n100.spr will
have 50 classifiers copied from tree_n50.spr and then 50 new
classifiers added. Note that now the "-a 4" option is necessary
because the format of the input data has changed due to addition of
weights.

AdaBoost output has a nice probabilistic interpretation: 

P(Y=1|X)/P(Y=-1|X) = exp(2*F(X))

where P(Y=1|X) and P(Y=-1|X) are probabilities for an event with
coordinates X to come from class 1 (signal) or class -1 (background),
respectively, and F(X) is the conventional AdaBoost output ranging
from -infty to +infty. By default trained AdaBoost returns the
probability of an event at point X being signal:
1/(1+exp(-2*F(X))). If you want to use raw AdaBoost output unmapped to
the [0,1] range, use "-s" option of the AdaBoost executables.


2.2 Bagging
-----------

Bagging (Bootstrap AGGregatING) means that many classifiers are
trained on bootstrap replicas of a training data set. To classify a
new event, responses of individual classifiers are summed up and
divided by the total number of individual classifiers.

The user can bag an arbitrary sequence of classifiers using
SprBaggerApp. To specify classifier configurations, use the same
syntax as booster.config mentioned in the previous section.

For historical reasons, I will keep another executable in the package
for bagging decision trees and random forest:
SprBaggerDecisionTreeApp.

One can bootstrap not only training points but also input dimensions
(random forest technology). This method can be invoked using the "-s"
option of SprBaggerDecisionTreeApp.

If individual classifiers optimize a certain criterion, e.g., signal
significance, bagging these classifiers is equivalent to optimizing
the same criterion on bootstrap replicas of the training sample. This
is a desirable feature if the user is interested only in optimization
of this specific criterion.

A typical application of bagged decision trees would look like this:

SprBaggerDecisionTreeApp -c 2 -n 50 -l 100 -o training.root -f tree.spr gauss2_uniform_2d_train.pat

(builds 50 decision trees, with at least 100 entries per terminal
node, optimizing the signal significance, saves the classifier
configuration into tree.spr and saves classified training data into
training.root)

SprBaggerDecisionTreeApp -n 0 -o validation.root -r tree.spr gauss2_uniform_2d_valid.pat

(reads the stored bagger from tree.spr, computes classifier
response for the validation data and saves ntuple to validation.root)

The two most important training parameters are "-s" and "-l". The
optimal number of sampled input features and the minimal size of leaf
nodes should be determined by examining the bagger performance on
(cross-)validation data. Breiman
(http://www.stat.berkeley.edu/users/breiman/RandomForests/) recommends
choosing the number of sampled input features small compared to the
dimensionality of the problem. I would recommend to try various values
of "-s" increasing exponentially. For example, if you have
100-dimensional data, you might try 1, 2, 4, 8, 16, 32, 64, and
100. In my experience, the optimal value of "-s" usually comes out
between D/2 and D, where D is the dimensionality of the input
data. The minimal leaf size, of course, needs to be optimized for each
value independently. Im my experience, the minimal leaf size is
usually fairly small - you can start with "-l 5" events per leaf and
assume that this could be fairly close to optimal.

Another classifier implemented in SprBaggerDecisionTreeApp is a
boosting algorithm, arc-x4. To use it, choose "-b"
option. Recommendations for the choice of "-s" and "-l" parameters
hold for this algorithm as well.

Note that this example, as well as the example in the AdaBoost
section, is mostly qualitative. The power of boosted and bagged
decision trees is most obvious in high-dimensional problems; an
example with 2D data is not intended to demonstrate the power of these
classifiers.


2.3 Decision tree
-----------------

A decision tree recursively divides input space into rectangular
regions (nodes). For each node the tree attempts to find the most
optimal split by choosing among all possible splits for all input
dimensions. The split yielding the largest figure of merit, according
to the user-supplied optimization criterion, is used to divide this
node into halves. If the largest figure of merit is less than the
original FOM computed for the unsplit node, this node becomes a leaf
(terminal node), classified either as signal (1) or background (0),
depending on the FOM value. The output of the tree training procedure
is a list of signal leaf nodes. After the leaves have been found, the
tree sorts the leaves by signal purity in the descending order and, if
it was requested by the user, merges the leaves to maximize the
overall FOM. The leaves included in the overall maximal-FOM set are
considered as signal regions, while the rest of the signal leaves not
included in the overall FOM set are re-classified to background
nodes. This selection procedure does not enforce continuity, and in
the end the signal leaves may be far apart from each other.

Decision trees have been introduced in the statistics literature two
decades ago and have become a popular data analysis tool. The
predictive power of an individual decision tree is typically worse
than that of flexible classifiers such as neural nets or boosted and
bagged decision trees. The main advantage of the decision tree is its
interpretability - rectangular regions can be easily visualized in
many dimensions.

The decision tree implemented here is different from popular
commercial implementations such as CART and C4.5. It is more
simple-minded because (at least for now) it can deal only with two
categories, signal and background. A conventional decision tree
implementation also involves a pruning algorithm for merging nodes
that belong to the same tree branch. A pruning algorithm typically
introduces a penalty on the tree complexity and attempts to reduce the
number of nodes at the cost of obtaining a slightly worse FOM with a
decreased complexity penalty. No pruning is attempted in this
implementation. Also, a conventional tree treats both categories
symmetrically and carries on training as long as the FOM with respect
to any input category can be improved. The tree implemented here can
work in two modes, symmetric and asymmetric. In the asymmetric mode,
it only finds optimal signal nodes, but no optimization is attempted
for background. This allows to use such inherently asymmetric FOM's as
signal significance S/sqrt(S+B) or a 90% upper limit. In the symmetric
mode, the tree works in the same way as a conventional tree would - it
finds each decision split by minimizing a fraction of correctly
classified events, Gini index or cross-entropy.

The stopping rule for the decision tree implemented here is set by the
minimal number of events per tree node. This parameter has to be
supplied by the user at tree construction. Depending on the chosen
optimization criterion, the tree performance can crucially depend on
this parameter. Try, for example

SprDecisionTreeApp -a 1 -c 3 -n 1 -m -v 1 gauss2_uniform_2d_train.pat

The tree will produce an insane number of nodes and in the end display
a message:

"Included 5318 nodes in category 1 with overall FOM=1 with 10000
signal and 0 background weights."

It means that the tree separated 10,000 signal events from background
events and grouped these signal events into 5318 nodes with 1.9 event
per node on average. This may seem impressive but if you run this tree
on validation data, you will find that the validation FOM is quite
poor because the tree is over-trained.

If you do now

SprDecisionTreeApp -a 1 -c 3 -n 5000 -m -v 1 gauss2_uniform_2d_train.pat

you will get

"Included 1 nodes in category 1 with overall FOM=0.915234 with 4632 signal and 429 background weights."

Since FOM now is significantly less than 1, it likely means that
the tree is under-trained. For this exercise, the optimal number of
events per node happens to be around 200, which you can easily
establish by looking at FOM computed on validation data:

SprDecisionTreeApp -a 1 -c 3 -n 200 -m -t gauss2_uniform_2d_valid.pat -v 1 gauss2_uniform_2d_train.pat

Note that without merging ("-m" option on the command line) these
results would be different.

For some optimization criteria, specifying 1 as the minimal number of
events per node can force the tree to create a separate node for each
event and lead to memory exhaustion.


2.4 Top-down tree
-----------------

The topdown tree (SprTopdownTree) implements the same training
algorithm as SprDecisionTree described in 2.3 but stores the
classifier configuration in a different way. While SprDecisionTree
stores the trained classifier as a list of rectangular nodes, the
topdown tree stores a full path from the tree root. This makes the
topdown tree less interpretable but faster for classification of new
events. To classify a new event with SprDecisionTree, it takes O(D*M)
operations, where D is the dimensionality of the problem and M is the
number of terminal nodes. The height of a balanced binary tree with M
terminal nodes is log(M)+1. Hence, the topdown tree reduces the
classification time by O(D*M/log(M)). In reality, this factor can be a
lot less because a) the topdown tree is not necessarily balanced, and
b) each terminal node may be defined by only a small subset of input
variables (which would reduce the classification time for
SprDecisionTree).

The topdown tree also offers optional continuous output instead of the
default discrete output (0/1) for the regular decision tree. The
continuous output is computed as w1/(w0+w1), where w1 and w0 are
fractions of signal and background weights in a terminal node.

Topdown trees should be the preferred choice if the user is interested
mostly in the classifier performance and not so much in the
interpretability of results. Topdown trees are currently the default
choice for the two main executables, SprAdaBoostDecisionTreeApp and
SprBaggerDecisionTreeApp. If you wish to use slower regular decision
trees, you can use "-j" option of the two executables. If you wish
discrete tree output for the bagging algorithm, you can use "-k"
option. The Discrete AdaBoost and epsilon-Boost algorithms generally
require that each individual boosted decision tree produce discrete
output; minimization of the exponential loss has been derived under
the assumption of discreteness of the base classifier. For Real
AdaBoost it is necessary, that each tree produce continuous
output. The tree options are switched automatically by the executable.

The single decision tree executable, SprDecisionTreeApp, continues
using regular decision trees. In this case, the prime concern is the
ease of interpretation, not speed.

Saved configuration files (with topdown trees) for the Bagger do
not retain information about whether decision trees were chosen to be
discrete or continuous. The default choice for SprTrainedBagger is
"continuous". If you wish to change this, you will need to do this
manually after you read the saved configuration. For example:

  SprTrainedBagger* bagger 
    = SprClassifierReader::readTrained<SprTrainedBagger>("saved_bagger.txt",
                                                         "Bagger");
  assert( bagger != 0 );
  bagger->setDiscrete();


2.5 Bump hunting
----------------

The idea behind bump hunting is very similar to that of a decision
tree - we search for rectangular boxes by optimizing a chosen figure
of merit. To find such a box, we look at all possible binary splits in
all dimensions. However, instead of recursively splitting input space
into multiple boxes of shrinking size (nodes), we attempt to find one
box with an overall optimal FOM. This is done in two steps:

a) Shrinking. At this stage, we attempt to shrink the signal box in
each dimension to optimize FOM. This shrinking crucially depends on
the "peel" parameter, a fraction of events that can be peeled off the
signal box in one iteration. The user should be very careful about
choosing this "peel" parameter. A low "peel" parameter makes the
algorithm slower and more conservative, while a high "peel" parameter
gives a high-speed and less robust performance. Note that the method
may fail to find statistically significant bumps both due to excessive
conservatism (low peel) and the lack of such (high peel).

b) Expansion. After the signal box shrunk to the minimal size, we
attempt to relax the bounds to increase FOM.

After the shrinking and expansion stages have been completed, we
remove events in the found box from the data set and repeat the
algorithm on the obtained subset to find a next box.

The outcome of this algorithm is a set of rectangular regions (bumps)
with the associated FOM. The user can request any number of bumps, and
then the algorithm will find them consecutively. In the case of
multiple bumps, the output of the bump hunter can be actually a bit
confusing because the bumps can overlap and even be enclosed one
inside another. Keep in mind that each found bump is removed from the
data before training is resumed to find a next bump; that is, in
reality the bumps don't overlap because each bump is merely a piece of
empty space from the point of view of bumps with higher indexes.

This method is intended for exploratory analysis, e.g., a blind search
for new physics phenomena and any analysis where the user wants to
find a rectangular signal box.

The ready-to-go executable is SprBumpHunterApp. 

Both SprBumpHunterApp and SprDecisionTreeApp store individual box
numbers into ntuples.


2.6 Fisher and logistic regression
----------------------------------

The executable is SprFisherLogitApp. It can store both training and
validation data into ntuples simultaneously. For example, you can do

SprFisherLogitApp -A -a 2 -m 3 -l -o training.out -t lambda-test.pat -p validation.out lambda-train.pat

(trains both linear and quadratic Fisher's (-m 3), as well as logistic
regression (-l), on lambda-train.pat and stores the training
tuple into training.out; validates Fisher on
lambda-test.pat and stores ntuple into validation.out)

Command-line options -e, -u and -i are valid only for logistic
regression. By default the starting point for logistic regression is
set to coefficients obtained by LDA (aka Fisher). If LDA fails, the
initial estimates for the regression coefficients are automatically
reset to zero. You can avoid using LDA for the initial estimate by
selecting "-i" option of the executable. If logistic regression fails
to converge, try reducing the update factor by choosing "-u" less than
1 (for example, 0.5 is a good starting choice). This reduces the rate
of convergence and makes the algorithm more stable.

For consistency with AdaBoost and in the general spirit of preferring
classifier output normalized to the [0,1] interval, L(Q)DA and LogitR
by default return output normalized to [0,1] (as of tag V04-04-00):
first the conventional output ranging from -infty to +infty is
computed and then it is mapped onto [0,1] by applying 1/(1+exp(-X))
transformation.  To see the conventional output, use "-s" option of
the executable or useStandard() method.


2.7 Neural networks
-------------------

The package implements a trainable backprop neural net and interfaces
to two SNNS classifiers, the standard backprop net and the radial
basis function net. The user does not have access to the training
mechanism supplied by SNNS. But if you train these classifiers using
the SNNS package, you can save the trained net into a *.net file. Then
you can run either SprStdBackpropApp or SprRBFNetApp, depending on the
type of the net you chose, to compute NN output for user-supplied data
and store the data and the NN output into an ntuple.

SprTrainedRBF implements the radial basis function net. It can be
used only for reading a saved SNNS configuration and applying it to
data. Spr(Trained)StdBackprop provides an original backprop neural net
implementation and also has the capacity to read saved SNNS
configurations.

SprStdBackpropApp implements both single backprop neural net and
boosted backprop neural nets. You can access the single neural net if
you use "-n 1" option of the executable (one AdaBoost training
cycle). If you use n>1, you will be training n boosted neural nets. If
you use n=0, the executable expects that you provide an input file
with a stored AdaBoost configuration.

The most important parameters of a neural net are its structure (-N),
learning rate (-L), and learning rate for initialization (-I). See
SprStdBackprop.hh for details on structure specification.

At initialization the neural net is trained on randomly selected
events using randomly generated learning rates. This is done to break
the initial neural net symmetry.

Training events are by default randomly permuted before training.

Here are a few examples of how the executable can be used:

SprStdBackpropApp -a 1 -n 1 -N '2:4:2:1' -l 100 -L 0.1 -d 5 -t gauss2_uniform_2d_valid.pat -f net.spr gauss2_uniform_2d_train.pat

Trains a single NN with 100 cycles from scratch. The NN configuration
is: 2 input nodes (must be always equal to the dimensionality of the
data!!!), 4 hidden nodes in the 1st hidden layer, 2 hidden nodes in
the 2nd hidden layer, and 1 output node (must be always 1 for
now!!!). The learning rate is 0.1. Display quadratic loss on
validation data every 5 cycles. Save NN configuration into net.spr.

Suppose you trained SNNS on these data earlier and now want to
convert SNNS configuration into SPR configuration. Do:

SprStdBackpropApp -a 1 -n 1 -S net.snns -l 0 -f net.spr gauss2_uniform_2d_train.pat

This simply converts SNNS format net.snns into SPR format net.spr.

You can resume training from SNNS format directly:

SprStdBackpropApp -a 1 -n 1 -S net.snns -l 100 -L 0.01 -f net200.spr -d 5 -t gauss2_uniform_2d_valid.pat gauss2_uniform_2d_train.pat

or from the converted SPR net:

SprStdBackpropApp -a 1 -n 1 -R net.spr -l 100 -L 0.01 -f net200.spr -d 5 -t gauss2_uniform_2d_valid.pat gauss2_uniform_2d_train.pat

You can use the obtained NN configuration as a starting point for
boosting:

SprStdBackpropApp -a 1 -n 10 -M 2 -E 0.1 -g 2 -R net200.spr -l 50 -L 0.01 -f boosted_net.spr -d 1 -t gauss2_uniform_2d_valid.pat gauss2_uniform_2d_train.pat

This takes the saved network net200.spr and uses it as a first
classifier in the boosting sequence. 10 more neural nets are trained
using the same network architecture and the 11 neural nets are saved
to boosted_net.spr. We now monitor exponential loss (-g 2) because it
is more appropriate for boosting.

Read the saved AdaBoost from a configuration file and run it on
validation data (results are saved into save.out):

SprStdBackpropApp -a 1 -n 0 -r boosted_net.spr -o save.out gauss2_uniform_2d_valid.pat

Do the same thing for a single NN you obtained earlier:

SprStdBackpropApp -a 1 -n 1 -l 0 -R net200.spr -o save.out gauss2_uniform_2d_valid.pat

If you would like to resume training from a saved AdaBoost
configuration, the executable forces you to choose a network structure:

SprStdBackpropApp -a 1 -n 10 -M 2 -g 2 -E 0.1 -r boosted_net.spr -f boosted_net_2.spr -L 0.01 -l 50 -N '2:6:3:1' -d 1 -t gauss2_uniform_2d_valid.pat gauss2_uniform_2d_train.pat

Note that the new structure 2:6:3:1 is different from 2:4:2:1 used
earlier. 10 more neural nets will be trained using 2:6:3:1 and
combined with the 11 nets trained earlier using 2:4:2:1. Also note
that -M option is redundant - the AdaBoost mode is read from
boosted_net.spr and set to Real, no matter what you specify on the
command line.


2.8 Combining classifiers
-------------------------

After several classifiers have been trained independently, it is
possible to combine them to obtain a better overall
performance. Spr(Trained)Combiner provides an interface for this
combining. The idea is to train a new powerful classifier on the
outputs of the combined classifiers. In the statistics literature,
this is sometimes referred to as "mixture of experts".

Starting with tag V00-06-00, the reworked combiner can combine an
arbitrary number of classifiers trained on arbitrary subsets of input
variables. For example, your input data is 6D with input variables
named x0, x1, ..., x5. You know that variables x0 and x2 need to be
grouped together (for example, they come from one detector
sub-system), variables x1, x3, and x5 form another group (another
detector sub-system), and variable x4 should be ignored. The input data
file train.pat has all variables filled out for each event with
missing values modeled as values outside the allowed range.  For
instance, the meaningful range for variable x3 extends from -1 to 1
and from 5 to 10; for events where you cannot measure variable x3
(missing value), you model it as a number somewhere outside the range,
e.g., -13.

The recommended sequence of actions looks like this:

1) Train your favorite classifiers on the subsets:

SprBaggerDecisionTreeApp -a 2 -n 10 -l 10 -V 'x0,x2' -f save_1.spr lambda-train.pat

For the 2nd classifier, you have to modify the executable to exclude
unreasonable values of x3. On top of the executable code, put your
functions (see example in src/exampleUserCuts.cc):

// accept all classes for input data
vector<int> myClasses() {
  return vector<int>();
}

// Define a list of variables used for user selection requirements.
vector<string> myVars() {
  vector<string> vars(1);
  vars[0] = "x3";
  return vars;
}

// Define cuts for specified variables using the specified order of variables.
// Return true if the point passes the cuts, false otherwise.
bool myCuts(const vector<double>& v) {
  if( (v[0]>-1. && v[0]<1.) || (v[0]>5. && v[0]<10.) ) return true;
  return false;
}

Following example in src/exampleUserCuts.cc, put the following in
main():

  // prepare pre-filter
  SprPreFilter pre;
  if( !pre.setSelection(myVars,myCuts,myClasses) ) {
    cerr << "Unable to set pre-filter." << endl;
    return 1;
  }

and modify the reader constructors to apply the constraint:

  SprSimpleReader reader(2,&pre);
  SprSimpleReader valReader(2,&pre);

Rebuild the executable by running 'make install' and run it:

SprBaggerDecisionTreeApp -a 2 -n 10 -l 10 -V 'x1,x3,x5' -f save_2.spr lambda-train.pat

Check the messages returned by the executable to make sure that you
see as many input events after the pre-selection cuts are applied as
you expect.

If you want to avoid the hassle of editing C++ code, you can simply
prepare two separate input files, one with varaibles x0 and x2 for the
1st sub-classifier and another one with variables x1, x3 and x5 and
with proper cuts on x3 imposed for the 2nd classifier. The two
training sets do not need to have anything in common - they can use
different input variables in a different order. The two essential
requirements are: a) an input variable must have the same name in all
input files for proper variable matching, and b) all variables used to
train sub-classifiers must be present in the training and test
datasets for the combiner.

2) Define input configuration files for the combiner. You need to
define one config file for each trained classifier plus a config file
for the global classifier to be trained on outputs of these trained
classifiers:

unix> cat classifier_1.config
Path:        save_1.spr
Name:        C1
Default:     0.5
Constraints: 0

Path needs to specify the path to the saved classifier config file
obtained in step 1. Name is an arbitrary name for the
classifier. Default is the default response value returned by the
classifier if input variables do not satisfy input constraints. The
output of the bagger ranges from 0 to 1. Therefore, if the failure to
satisfy the input constraints does not qualify this event as
background or signal, choose 0.5 as the default value. In this case,
there are no constraints, as you can see on the constraints line, and
so the chosen default value is irrelevant.

For the 2nd classifier, you need to specify the constraint on variable
x3:

unix> cat classifier_2.config
Path:        save_2.spr
Name:        C2
Default:     0
Constraints: 1
x3  2  -1. 1.   5. 10.

First, you specify the number of constraints (1 in this case because
you impose constraints only on variable x3). On the next lines you
need to specify the constraints. Put the name of the input variable
first, then the number of allowed intervals and all allowed intervals
on the same line. If you need to impose constraints on another input
variable, change 1 to 2 and insert another line at bottom.

In this case, if the value of x3 is outside of the allowed range, this
is considered as a symptom of the event being background. The default
response value is set to 0.

Make a global config file for the combiner:

unix> cat global.config
StdBackprop 2:4:2:1 50 0.1 0 0.1

This uses the same syntax used by SprBoosterApp or SprBaggerApp. See
booster.config for detail. In this case, you would like to train a
neural net with 2 input units because you have trained 2 classifiers
on data subsets.

3) Train the combiner:

SprCombinerApp -a 2 -f global.spr 'classifier_1.config,classifier_2.config' global.config lambda-train.pat

4) Study the performance of the combiner on test data:

SprOutputWriterApp -a 2 global.spr lambda-test.pat save.out

Note that you do not need to specify explicitly input variables in
steps 3 and 4. SprCombinerApp and SprOutputWriterApp know that
variable x4 has been excluded because neither of the trained
sub-classifiers uses it.

Also note that in the example above the same training data, train.pat,
has been used for training classifiers on subsets and the combiner. If
the classifiers on subsets severely overtrain (which in fact may be
the case for the bagger), training the combiner on the overtrained
responses may be far from optimal. In general, for this exercise you
would need to prepare 2 training sets, one to train on subsets and
another one to train the combiner.


2.9 Recommendations: What classifiers to use and when
-----------------------------------------------------

These should be viewed as highly approximate. It is certainly not my
intention to impose my views of what is a "better" or "worse"
classifier on other physicists.

Every classifier has a set of features: predictive power, speed and
robustness of the training procedure, interpretability of results,
performance in high-dimensional problems etc. There is no such thing
as the "best" classifier; every tool is suited for its purpose.

If you are mostly concerned with speed, I suggest
boosted binary splits. This classifier trains very quickly and
produces a decent, although hardly optimal, separation of signal from
background.

If, due to whatever reason, you want to find a rectangular signal
region, you should use the bump hunter. This method should be also
good in situations when you are performing a blind search for an
excess of data above the simulated process.

If you are mostly concerned with the quality of signal/background
separation, you should use a neural net, boosted decision trees
or random forest (Bagger).

If your input data live in a low-dimensional space (dimensionality is
less than 10), if all input variables are continuous and there are no
strong correlations among them, and if the structure of the input data
is more or less simple (i.e., there are no multiple peaks), a standard
feedforward backpropagation neural net should do a great job for
you. This is not to imply that the neural net should perform better
than the boosted decision trees or random forest. I would make no
predictions for what classifier of the mentioned three will perform
better in a specific low-dimensional problem.

The neural net suffers from a variety of problems in high-dimensional
settings. When you add more dimensions, you generally need to expand
the hidden layer as well to capture the increasing complexity of the
data. If the size of the hidden layer is proportional to that of the
input layer, the training and response time of a neural net increase
quadratically. With more than one hidden layer, this dependence is
even worse. Also, the neural net can get confused if it is presented
with strongly correlated variables or variables of the mixed type
(continuous and discrete).

This is why in high-dimensional settings (dimensionality is 20 or
more), boosted decision trees and random forest are faster and more 
reliable classification tools. The training and response time of these
classifiers generally scales linearly with dimensionality.

If you are mostly interested in obtaining a good _average_ separation
between signal and background, e.g., you would like to get two
distinct one-dimensional likelihood shapes and use them in a fit to
data, or if you would like to access the whole "signal purity vs
signal magnitude" curve, I suggest that you use either
boosted decision trees or random forest with symmetric optimization 
criteria 5 or 6, that is, Gini index and cross-entropy.

If you are only interested in one specific criterion such as the
maximal signal significance or the minimal 90% upper limit, I suggest
that you try SprBaggerDecisionTreeApp and optimize this criterion
directly by specifying an appropriate "-c" option.

Do not overdo!!! For many problems, you can get fairly good results
with quick and robust classifiers such as boosted binary splits or
a single decision tree. For example, running boosted or random forest
to separate two bivariate Gaussians from uniform background
(gauss2_uniform_2d_train.pat) does not make much sense (even though
this dataset is used for illustrative examples here).

SprInteractiveAnalysisApp has been provided to help people quickly
compare performance of various classifiers on relatively small
datasets in not too many dimensions. Syntax should be
self-explanatory.


2.10 How to choose parameters for boosted and bagged decision trees
------------------------------------------------------------------

The most important input pairameter for boosted decision trees is
the minimal number of events per terminal node of a decision tree,
SprAdaBoostDecisionTreeApp gets this parameter from "-l" option on 
the command input line. SprBoosterApp reads this parameter from
the configuration file. The easiest way to choose an optimal value 
for this parameter is to monitor the classifier performance on 
validation data.

AdaBoost is designed to minimize the exponential loss. To choose the
optimal leaf size, monitor the exponential loss for the validation
data:

unix> SprAdaBoostDecisionTreeApp -a 1 -n 20 -l 100 -t gauss2_uniform_2d_valid.pat -d 1 gauss2_uniform_2d_train.pat

Validation Loss=0.52714 at cycle 1
Validation Loss=0.46702 at cycle 2
Validation Loss=0.44809 at cycle 3
Validation Loss=0.449999 at cycle 4
Validation Loss=0.455101 at cycle 5
Validation Loss=0.462101 at cycle 6
Validation Loss=0.474901 at cycle 7
Validation Loss=0.488699 at cycle 8
Validation Loss=0.502885 at cycle 9
Validation Loss=0.50625 at cycle 10
Validation Loss=0.509496 at cycle 11
Validation Loss=0.535736 at cycle 12
Validation Loss=0.549812 at cycle 13
Validation Loss=0.565217 at cycle 14
Validation Loss=0.595657 at cycle 15
Validation Loss=0.611038 at cycle 16
Validation Loss=0.636845 at cycle 17
Validation Loss=0.659387 at cycle 18
Validation Loss=0.683962 at cycle 19
Validation Loss=0.700659 at cycle 20

The exponential loss increases. Probably L=100 is not a good
choice. Let us try a larger L:

unix> SprAdaBoostDecisionTreeApp -a 1 -n 20 -l 8000 -t gauss2_uniform_2d_valid.pat -d 1 gauss2_uniform_2d_train.pat

Validation Loss=0.815399 at cycle 1
Validation Loss=0.803473 at cycle 2
Validation Loss=0.771938 at cycle 3
Validation Loss=0.756562 at cycle 4
Validation Loss=0.747749 at cycle 5
Validation Loss=0.741897 at cycle 6
Validation Loss=0.737569 at cycle 7
Validation Loss=0.73411 at cycle 8
Validation Loss=0.730116 at cycle 9
Validation Loss=0.727139 at cycle 10
Validation Loss=0.724745 at cycle 11
Validation Loss=0.723074 at cycle 12
Validation Loss=0.721264 at cycle 13
Validation Loss=0.720109 at cycle 14
Validation Loss=0.718357 at cycle 15
Validation Loss=0.716691 at cycle 16
Validation Loss=0.715792 at cycle 17
Validation Loss=0.714532 at cycle 18
Validation Loss=0.713479 at cycle 19
Validation Loss=0.712872 at cycle 20

Exponential loss decreases but we can do better. One more try:

unix> SprAdaBoostDecisionTreeApp -a 1 -n 20 -l 1500 -t gauss2_uniform_2d_valid.pat -d 1 gauss2_uniform_2d_train.pat

Validation Loss=0.650332 at cycle 1
Validation Loss=0.516325 at cycle 2
Validation Loss=0.482314 at cycle 3
Validation Loss=0.460987 at cycle 4
Validation Loss=0.454166 at cycle 5
Validation Loss=0.449057 at cycle 6
Validation Loss=0.435003 at cycle 7
Validation Loss=0.426111 at cycle 8
Validation Loss=0.422804 at cycle 9
Validation Loss=0.416456 at cycle 10
Validation Loss=0.40981 at cycle 11
Validation Loss=0.407647 at cycle 12
Validation Loss=0.406386 at cycle 13
Validation Loss=0.406077 at cycle 14
Validation Loss=0.405301 at cycle 15
Validation Loss=0.40665 at cycle 16
Validation Loss=0.40524 at cycle 17
Validation Loss=0.403948 at cycle 18
Validation Loss=0.403166 at cycle 19
Validation Loss=0.399208 at cycle 20

The loss values are better. By trying various values of "-l"
parameter, one can find that L=1500 is about optimal.

For this problem, two bivariate Gaussians on top of uniform
background, separating signal from background is easy. You certainly
don't need many boosted trees for that - in fact, you can separate
signal from background fairly well with a single decision tree! This
example is merely for illustration.

Let us now find the optimal leaf size for the bagger. Suppose we are
interested in the quadratic loss (-g 1 option of the executable).
Naively, one could assume that the optimal value should be the same as
for the booster:

unix> SprBaggerDecisionTreeApp -a 1 -g 1 -n 20 -l 1500 -t gauss2_uniform_2d_valid.pat -d 1 gauss2_uniform_2d_train.pat

Validation FOM=0.101408 at cycle 1
Validation FOM=0.0958078 at cycle 2
Validation FOM=0.0941453 at cycle 3
Validation FOM=0.0911666 at cycle 4
Validation FOM=0.0873188 at cycle 5
Validation FOM=0.0847348 at cycle 6
Validation FOM=0.0843446 at cycle 7
Validation FOM=0.0890755 at cycle 8
Validation FOM=0.0895145 at cycle 9
Validation FOM=0.0910927 at cycle 10
Validation FOM=0.089789 at cycle 11
Validation FOM=0.0879379 at cycle 12
Validation FOM=0.0879443 at cycle 13
Validation FOM=0.0864982 at cycle 14
Validation FOM=0.085486 at cycle 15
Validation FOM=0.0849834 at cycle 16
Validation FOM=0.0847154 at cycle 17
Validation FOM=0.0843778 at cycle 18
Validation FOM=0.0840525 at cycle 19
Validation FOM=0.0838303 at cycle 20

Let us try another choice for the leaf size: 50.

unix> SprBaggerDecisionTreeApp -a 1 -g 1 -n 20 -l 50 -t gauss2_uniform_2d_valid.pat -d 1 gauss2_uniform_2d_train.pat

Validation FOM=0.084895 at cycle 1
Validation FOM=0.0770321 at cycle 2
Validation FOM=0.0680597 at cycle 3
Validation FOM=0.0643376 at cycle 4
Validation FOM=0.0611588 at cycle 5
Validation FOM=0.0618565 at cycle 6
Validation FOM=0.0613833 at cycle 7
Validation FOM=0.0652366 at cycle 8
Validation FOM=0.0638901 at cycle 9
Validation FOM=0.0647727 at cycle 10
Validation FOM=0.0630297 at cycle 11
Validation FOM=0.0622102 at cycle 12
Validation FOM=0.0626738 at cycle 13
Validation FOM=0.0616809 at cycle 14
Validation FOM=0.0608163 at cycle 15
Validation FOM=0.0616452 at cycle 16
Validation FOM=0.0625021 at cycle 17
Validation FOM=0.0616811 at cycle 18
Validation FOM=0.0610225 at cycle 19
Validation FOM=0.0603946 at cycle 20

Quadratic loss is less than in the previous trial. Most certainly,
50 is a better option than 1500. Let us go even to smaller leaves:

unix> SprBaggerDecisionTreeApp -a 1 -g 1 -n 20 -l 5 -t gauss2_uniform_2d_valid.pat -d 1 gauss2_uniform_2d_train.pat

Validation FOM=0.0875863 at cycle 1
Validation FOM=0.080353 at cycle 2
Validation FOM=0.0714745 at cycle 3
Validation FOM=0.0670627 at cycle 4
Validation FOM=0.0638389 at cycle 5
Validation FOM=0.0640173 at cycle 6
Validation FOM=0.0635259 at cycle 7
Validation FOM=0.0666818 at cycle 8
Validation FOM=0.0652588 at cycle 9
Validation FOM=0.0661904 at cycle 10
Validation FOM=0.0645742 at cycle 11
Validation FOM=0.0637672 at cycle 12
Validation FOM=0.0640231 at cycle 13
Validation FOM=0.0630114 at cycle 14
Validation FOM=0.0623262 at cycle 15
Validation FOM=0.0630325 at cycle 16
Validation FOM=0.0637906 at cycle 17
Validation FOM=0.0629989 at cycle 18
Validation FOM=0.0623234 at cycle 19
Validation FOM=0.06177 at cycle 20

These FOM values are a little worse than in the previous example. So
probably 50 is about optimal.

Note the dramatic difference between boosted and bagged decision
trees. While boosted trees typically want to have large terminal
nodes, bagged trees usually benefit from making the terminal node
size fairly small.


2.11 Cross-validation
---------------------

Cross-validation has been implemented for three executables:
SprAdaBoostDecisionTreeApp, SprBaggerDecisionTreeApp, and
SprDecisionTreeApp. The purpose of cross-validation is to choose an
optimal set of the decision tree parameters if no validation data are
available. In this case, the supplied training data are split into
several equal pieces (as specified by "-x" option). These pieces are
then excluded one by one from the training sample. The classifier
(AdaBoost or Bagger) is trained on the training data with one piece
excluded and then its performance is evaluated on the missing
piece. At the end, the FOM obtained by averaging the FOMs from all
pieces is returned to the user. A typical application of the
cross-validation algorithm would look like this:

SprBaggerDecisionTreeApp -a 1 -g 1 -n 20 -x 5 -q '5,10,20,50,100,1000,2000,5000' gauss2_uniform_2d_train.pat

This will train 20 bagged decision trees for each specified minimal
node size. That is, the user will train 8 baggers, each using 20
bagged decision trees. In the end you will get (quadratic loss
displayed):

Cross-validated FOMs:
Node size=       5      FOM= 0.0591947
Node size=      10      FOM= 0.0604726
Node size=      20      FOM= 0.0595813
Node size=      50      FOM= 0.0586453
Node size=     100      FOM= 0.0621193
Node size=    1000      FOM= 0.0830538
Node size=    2000      FOM=  0.104705
Node size=    5000      FOM=  0.130985

This cross-validation exercise tells you that L=50 is close to the
optimal value.

The "-g" option of the two main executables,
SprAdaBoostDecisionTreeApp and SprBaggerDecisionTreeApp, lets you
choose an average per-event loss as the cross-validation
figure-of-merit. At the moment, two kinds of per-event loss are
implemented: squared loss and exponential loss. If no "-g" option is
specified, the optimization FOM (e.g., Gini index or cross-entropy) is
used by default for cross-validation by the bagger; exponential loss
is used by default by AdaBoost. If Gini index or any other
optimization FOM is used, you should choose the set of parameters that
gives you the largest FOM. By convention adopted in the package, large
values of the optimization FOM, unlike per-event loss, signify a high
quality of separation.


2.12 Multi class learning
-------------------------

Spr(Trained)MultiClassLearner implements a multi-class learning
algorithm by training a series of binary classifiers for two-class
problems. The reduction of the multi-class problem to a series of
two-class problems is defined by an indicator matrix of the size K*L,
where K is the number of classes and L is the number of binary
classifiers to be built. Matrix elements can take only 3 values: -1, 0
and 1. For each column of the matrix, 1 means that this class is
treated as signal, -1 means that this class is treated as background,
and 0 means that this class does not participate in this binary
problem. Two popular training strategies have been implemented:
one-vs-all and one-vs-one. For the one-vs-all strategy, the indicator
matrix is of size K*K with diagonal elements equal to 1 and
off-diagonal elements equal to -1. For the one-vs-one strategy, the
indicator matrix is of size K*L, where L=K*(K-1)/2; in each column
there is one 1 and one -1, while all other elements are zeros. The
user can specify any other indicator matrix. For example, if one has a
problem with background (class 0) and two similar signals (classes 1
and 2), one could train one classifier to separate the joint signal
from the background and then the two signals from each other. In this
case the indicator matrix would look like this: 
Row/Column |  0  1
------------------
 0         | -1  0
 1         |  1  1
 2         |  1 -1

To provide an arbitrary indicator matrix, the user must construct
SprMutiClassLearner in the User mode. The two other modes, OneVsAll
and OneVsOne, will force regeneration of the indicator matrix
according to the described templates. Running SprMultiClassApp, the
user needs to choose "-e 3" for the user-defined mode and use "-i"
option to specify an indicator matrix in an input file. See
indicator.config for a sample.

After training is completed, new data are classified using the
user-specified per-event loss for each row of the indicator
matrix. Each of the L classifiers is used to compute response f_l for
a given point; l=1,...,L. Then average loss is evaluated for each row
of the indicator matrix. For example, for quadratic loss we have
Loss_k = \sum_{l=1}^L (Ikl-f_l)^2, where Ikl is an element of the
indicator matrix (k-th row and l-th column). The point is classified
as category k if Loss_k is the least of loss values computed for all
rows. SprDataFeeder allows the user to save loss values computed for
each row of the indicator matrix as well as the overall integer
classification label for each data point.

The executable for multi-class learning implemented in the package is
SprMultiClassApp. It lets you use any classifier for binary class
training. The restriction at the moment is that this has to be the
same classifier for each pair of classes, that is, you cannot use, for
example, a neural net to separate class 1 from class 2 and then a
decision tree to separate class 1 from class 3. You can either use a
neural net in both cases or a decision tree in both cases. The
classifier is specified in a config file, similar to booster.config
except it only takes one topmost entry.  Due to certain specifics,
this executable does not allow to resume training from a saved
configuration file. Therefore, "-r" command line option automatically
assumes zero training cycles and can be used only to read from the
saved configuration file and compute classifier response for new
data. The "-y" option is mandatory - the user must specify all classes
to be included in the multi-class learning algorithm.

As an example, try:

> SprMultiClassApp -a 1 -e 1 -y '0,1,2,3,4' -c multi.config -f save.spr -t gauss4_uniform_2d_valid.pat gauss4_uniform_2d_train.pat

where multi.config consists of 2 lines:

AdaBoost 20 1 0 0.01
TopdownTree 5 0 1000

This will train 20 boosted decision trees for each column of the
indicator matrix. AdaBoost, unlike all other classifiers, requires 2
input lines in the config file instead of one - the 2nd line must
specify the weak classifier to be used with AdaBoost.

Also, try

> SprMultiClassApp -a 1 -e 2 -y '0,1,2,3,4' -c multi.config -f save.spr -t gauss4_uniform_2d_valid.pat gauss4_uniform_2d_train.pat

and then

> SprMultiClassApp -a 1 -y '0,1,2,3,4' -r save.spr -o save.out gauss4_uniform_2d_valid.pat

to see distributions for validation data.


3. Data and filters
-------------------

Each data point, SprPoint, is described by a vector of its
coordinates, its class and its index (a non-negative number assigned
by the user to distinguish points). SprData is a collection of
SprPoint's.

In many applications we need to weight data points and impose
cuts. This can be accomplished by imposing a filter. Every filter that
can be used with the package must inherit from SprAbsFilter. Note that
pretty much all classes, e.g., classifiers, that need access to data
do not talk to data directly; instead they get access to a filter
applied to this data. If you don't need any filtering, you can use
SprEmptyFilter.

SprAbsFilter itself is capable of filtering on 
1) event class 
2) event index 
The index here applies not to the user-defined index of each
point but to the flat index in the list of data points ranging from 0
to (length-1) given by the order in which the points were added to
SprData. User-defined indexes of SprPoint's are used simply to give
each point a unique id number.

Filter can also apply weights to events. These weights are not
normalized to unit sum. If you wish to keep weights normalized, you
need either to call normalizeWeights() method after filter
construction and after every filter() operation or supply normalized
weights to the filter constructor.

SprAbsFilter has 3 pure virtual methods that must be implemented by
specific filters: setCut(), resetCut() and pass(). The first two set
and remove filter requirements. The 3rd one determines if a data point
satisfies the requirements imposed by setCut(). At the moment, only
two filters are implemented: 1) SprEmptyFilter which does not impose
any cuts and simply reproduces the base SprAbsFilter functionality, and
2) SprBoxFilter which imposes rectangular cuts on the input space.

To put filtering cuts in effect, the user needs to run filter()
method. The filtering cuts and weights can then be removed with
clear(). Note that clear() in SprAbsFilter restores the filter to its
original state, that is, all cuts are removed and the weights are
reset to the weights with which the filter was constructed.

To reduce memory consumption, the user can apply irreversibleFilter()
method. If irreversibleFilter() is used, events that do not satisfy
the imposed cuts are removed permanently and cannot be restored by
clearing the filter. This method cannot be applied if SprData owned by
the filter owns SprPoint's. 

Each filter implementation should also have a
copy-constructor. However, for SprAbsFilter the copy-constructor does
not do the usual deep copying. Its purpose in this case is to provide
a consecutive filter. SprAbsFilter's copy-constructor copies the
current filter's state, that is, weights and all imposed cuts. Only
events that satisfy these cuts are fed into the new filter. If you
create filter 2 out of filter 1 using a copy-constructor, apply some
extra filtering to filter 2 and then call clear() on filter 2, filter
2 will restore weights and cuts used at its construction. That is, you
will never get access to the original weights and uncut data used by
filter 1 - unless, of course, you call clear() on filter 1 before you
copy-construct filter 2.

Note that the original SprEmptyFilter produced by SprSimpleReader owns
the input data. If you impose consecutive filters, they will hold
pointers to the data owned by the original filter. Therefore, you are
not allowed to delete the original filter - as long as you need access
to the input data. If you delete the original filter, consecutive
filters will point to a non-existent piece of memory.


4. Imposing cuts
----------------

Cuts are imposed using an SprCut typedef specified in SprDefs. SprCut
is a vector of pairs. Each pair in the vector represents lower and
upper bounds. The idea is that the cut on a quantity is satisfied if
this quantity lies between the lower and upper bounds for any pair in
the vector. A simple one-sided cut is modeled as a vector with only
one pair which has either the lower or upper bound equal to the
numeric limit on double (see SprUtils).


5. Treatment of input classes
-----------------------------

Classes in data input must be coded as integers. For the purpose of
classification, however, the user can group classes in any way s/he
likes. This functionality is implemented in SprClass. Each SprClass
has a vector of integer numbers and a negation flag. For instance,
input data has 5 classes numbered from 0 to 4. If the user wants to
treat classes 1 and 3 as signal and all the others as background, s/he
should make two SprClass objects. There are several ways of making
them:

a) 1st SprClass object has integers 1 and 3 and the negation flag is
set to false. 2nd SprClass object has integers 0, 2, and 4, and the
negation flag is also false.

b) 1st SprClass object has integers 1 and 3 and the negation flag is
set to false. 2nd SprClass object has integers 1 and 3, and the
negation flag is set to true.

c) ...

In case (b), the meaning of the 2nd SprClass object is "any class but
1 and 3". For 5 input classes, this is equivalent to "classes 0, 2,
and 4".

Most executables have "-y" command-line option which lets the user make
this choice interactively. The corresponding C++ method is
SprAbsFilter::filterByClass(). For description of syntax, see
SprAbsFilter.hh.

Content of each SprClass object is printed out using the "<<"
operator. It shows all classes as a list of integers separated by
commas and the negation flag in parentheses as either +1 (no negation)
or -1 (negation is in effect).

In this approach, original event classes specified in input data are
stored, unchanged, into an output ntuple. This allows the user to see
what specific processes contribute to specific regions of the
classifier output. The ntuple does not carry information about what
class was treated as background and what class was treated as signal;
in most situations it is fairly easy to figure that out just by
looking at the correlation between the class number and the classifier
output, but in principle the user has to keep an independent record of
how the classes were split into signal and background for the purpose
of this classification job. 


6. Estimation of variable importance
------------------------------------

Tools for variable selection fall in two groups: 1)
classifier-independent and 2) classifier-specific methods.

The classifier-independent tool implemented in the package
(SprExploratoryAnalysisApp) computes correlations between variables
and the class label. SprDataMoments implements two methods:
correlClassLabel() to compute corr(X,Y) and absCorrelClassLabel() to
compute corr(|X-EX|,Y), where X is the variable in question, EX is its
expectation and Y is the class label. In principle, the larger is the
magnitude of the correlation, the more powerful is this variable for
classification. In reality, this method for variable selection is not
very reliable. It is easy to construct an example where corr(X,Y)=0
but in fact X is a powerful classification variable. It is harder (but
possible) to construct an example where both corr(X,Y) and
corr(|X-EX|,Y) are close to zero but variable X is powerful
nevertheless. The reverse is not true: If one of these correlations is
close to 1 or -1, this is most likely a powerful classification
variable.

For decision trees, you can count the number of decision splits on
each input variable and estimate the change in the split criterion FOM
due to this variable. The change in the FOM is a more reliable measure
of the variable importance than the split counting. Both these options
are invoked by the "-i" command-line option with the
decision-tree-related executables.

SprVariableImportanceApp estimates the importance of each input
variable for the applied classifier. It randomly permutes class labels
in the provided dataset for each input variable in turn and estimates
an increase in the classification loss (either quadratic or
exponential) due to this mislabeling. The more important the variable,
the greater the increase in the classification loss. At the end,
variables are displayed in the order of descending importance. The
user can specify the number of permutations per variable over which
the increase in loss is averaged. The default is one permutation but
it is recommended to use more than one for more accurate results. You
can always use quadratic loss (default choice) since classifiers whose
output ranges from -infty to +infty automatically map the output onto
[0,1] in that case. The reverse is not true - if you choose
exponential loss, you can obtain nonsensical results for classifiers
that by default return values within [0,1]. 

These methods only provide crude estimates. The best (and
time-consuming) approach is to try all or most variable combinations
for each classifier and select the combination that gives the best
performance. Because boosted decision trees and random forest perform
well in high dimensions, the usual strategy is to start with all
variables for these classifiers and throw them away as long as the
classification power does not deteriorate past the level you can
tolerate.


7. Handling input variables
---------------------------

If input data are read from a Root file, the user specifies explicitly what
variables are taken from the input ntuple. If input data are read from an Ascii
file, all variables included in the Ascii file are by default read in. If you
want to exclude some of them, you can do so by using "-z" option of the
executables. 

"-V" command-line option of most executables lets the user include
only specified variables. Again, it works only for Ascii input.

Generally, it is the responsibility of the user to keep track of what
variables were used for training and supply the same variables in the
same order to a trained classifier. That is, if you exclude certain
variables from training using "-z" option, you have to remember to
exclude the same variables when you compute classification values for
this dataset. Note that the list of variables used for training is
saved at the bottom of each trained classifier configuration file.

To make your life easier, some executables have "-M" option. This
option allows to map variables used for training (included at the
bottom of the classifier configuration file) onto variables available
in input data. If "-M" option is provided, you don't have to remember
what variables were used for training. You have to make sure that
identical variables have identical names in training and test datasets.

Sometimes you want to exclude variables from training but store them
into the output root (or Ascii) file. This can be done using "-Z"
option. The "-Z" option has no effect on variables used for training;
it only asks the executable to exclude certain variables from
computation of the classifier response which is stored into the output
ntuple. A typical application of the "-Z" option would look like this:

unix> SprAdaBoostDecisionTreeApp -a 1 -n 100 -z 'var1,var2' -f save.spr train.pat

and then

unix> SprAdaBoostDecisionTreeApp -a 1 -n 0 -Z 'var1,var2' -r save.spr -o test.root test.pat

This will train boosted decision trees using all input variables except var1
and var2 and then compute the classifier response for the test data and store
these variables into test.root as well. For comparison,

unix> SprAdaBoostDecisionTreeApp -a 1 -n 0 -z 'var1,var2' -r save.spr -o test.root test.pat

would do the same thing without storing var1 and var2 into the output ntuple.

Starting with SPR-6, the user can filter data, apply variable
transformation and compute the class label for each event defined as a
function of the event coordinates. All these operations are performed
as the data is being read from a file. An example is shown in
exampleUserCuts.cc. Keep in mind that selection requirements are
applied before transformations - you always cut on the untransformed
values. These methods are implemented in SprPreFilter and they have
nothing to do with generic filtering described in Section "3. Data and
filters". SprAbsFilter described in section 3 is applied to data that
has been stored in memory and converted into SPR format. Most of
SprAbsFilter methods hide pieces of data from the user but do not
remove them permanently from memory; these can be reversed and the
user can get access to the full dataset again. SprPreFilter selection
is applied while data is being read from input files. SprPreFilter
cuts and transformations have permanent effect - for example, events
that do not pass these cuts never get stored in memory.


8. Formats for data input and output
------------------------------------

Input is implemented from Ascii and Root files.

The Ascii input format is close to that of SNNS. There are two
essential rules:
- everything to the right of '#' is treated as comments
- an input line must contain at least as many numbers as the dimensionality
  of the input space; these are considered point coordinates
The point class can be supplied either on the same line or on a separate line.
For details and acceptable Ascii formats, see SprSimpleReader.hh.

If you have a *.pat file readable by SNNS, you can easily turn it
into a file readable by SprSimpleReader. To do this,
a) comment out the SNNS header by placing '#' at the beginning of each line
b) the 1st non-comment line must start with an integer number which represents
   the dimensionality of input space
c) the 2nd non-comment line must show names of input variables, at least as
   many as the specified number of dimensions; spaces in the variable
   names are not allowed
The rest of the *.pat file can be kept as is.

For details on Root input, see SprRootReader.hh.

As of Sourceforge tag V07-02-00, if the package was built against
Root, the user can choose between input and output from/to Ascii and
Root files. For Ascii input, the user must specify -a flag for all
executables with an appropriate integer mode. If -a is omitted or "-a
0" is specified, the executable assumes that input data must be
fetched from Root files. For output, the default choice is Root. To
output data into Ascii files, the user must specify -A flag on the
command line.


9. Computing output for trained classifiers
-------------------------------------------

Data, event weights and classifier outputs can be stored into tuples
using SprDataFeeder. The feeder can work with any SprAbsWriter. At
present there are 2 implemented writers, SprRootWriter, capable of
storing data into Root, and SprAsciiWriter for data storage into Ascii
files. The feeder will feed all data points obtained from an input
filter with classifier outputs to the writer. You can add as many
classifiers to the output as you like using addClassifier() method of
the feeder.

Spr{Root,Ascii}Writer will save input coordinates for each point with
column names extracted from the input data file and with the output of all
classifiers. Besides, it will always fill the following 3 columns:
- "index" for user-specified event index
- "i" for event class ("classification" in case of SprRootWriter)
- "w" for event weight ("weight" in case of SprRootWriter)

SprOutputWriterApp reads the saved configuration of any trained classifier,
computes classifier responses for the supplied data and saves output 
into a file. Prior to tag V05-00-00 this fuctionality was distributed among
several executables. For example, to read the saved AdaBoost configuration
from a file and apply it to data, the user would have to specify zero
training cycles "-n 0" and a file to read from using "-r" option of the
corresponding AdaBoost executable. SprOutputWriterApp is a unified 
recommended replacement.


10. Installation instructions
-----------------------------

See INSTALL.


11. How to use trained classifiers in your C++ code
---------------------------------------------------

This syntax has changed in tag V05-00-00. Now all trained classifiers
are read in using the unified interface of SprClassifierReader. For
example, to apply the saved AdaBoost configuration to data, the user
would have to do:

  SprAbsTrainedClassifier* ada 
    = SprClassifierReader::readTrained("saved_adaboost.spr");
  assert( ada != 0 );
  vector<double> input = ...;
  double ada_output = ada->response(input);
  ....
  delete ada;// delete after you are done

Similarly, for Bagger. 

If you know what classifier is saved in the configuration file, you
might want to use the type-safe syntax:

  SprTrainedAdaBoost* ada
    = SprClassifierReader::readTrained<SprTrainedAdaBoost>(
                             "saved_adaboost.spr","AdaBoost");
  assert( ada != 0 );

In this case the read will succeed only if the saved classifier is
indeed AdaBoost. (For this to work, make sure that template
instantiations in SprClassifierReader are uncommented!! Since they
break package compilation for some compilers, I may keep them
commented out in the source code.)

For the multi-class learner, you need to use SprMultiClassReader:

  SprMultiClassReader multiReader;
  if( !multiReader.read("saved_multiclass.spr") ) abort();
  SprTrainedMultiClassLearner* multiclass = multiReader.makeTrained();
  assert( multiclass != 0 );
  vector<double> input = ...;
  map<int,double> output;
  int category = multiclass->response(input,output);
  ....
  delete multiclass;// delete after you are done


12. Working in Root-free environment
------------------------------------

SprInteractiveAnalysisApp and SprOutputAnalyzerApp are the two
executables that allow one to avoid using, to a large extent, any
graphics packages. If you built the package without Root, you can use
the following sequence to assess the performance of classifiers:

a) Train a bunch of classifiers, for example:

SprBaggerDecisionTreeApp -a 1 -n 100 -l 5 -f bagger.spr train.pat
SprAdaBoostDecisionTreeApp -a 1 -n 100 -l 1000 -f ada.spr train.pat

b) Compute output for test data:

SprOutputWriterApp -a 1 -A -C 'ada,bag' 'ada.spr,bagger.spr' test.pat test.out

c) Analyze the Ascii output:

SprOutputAnalyzerApp -C 'ada,bag' test.out 

See comments in SprOutputAnalyzerApp.cc.

If you built the package with Root, you can't use step (c) but, of
course, you could and should use steps (a) and (b) (without the "-A"
flag).

For small data sets in not too many dimensions, you can combine all
these steps in one and compare several classifiers using
SprInteractiveAnalysisApp:

SprInteractiveAnalysisApp -a 1 train.pat test.pat


13. Working in Root environment
-------------------------------

Starting with SPR release 7, the user can run SPR interactively from
Root session. See root/spr_tutorial.C. The package needs to be built
against Root. This functionality is provided by the SprRootAdapter
class. See the interface in include/StatPatternRecognition for a list
of all available options.

I strongly advise against running CPU-intensive jobs within Root
environment, whether interactive or batch. The SPR Root wrapper has
been provided to let the user run interactive analysis on small
datasets in not too many dimensions and give the user access to
graphics. If you need to train on datasets of appreciable size, do it
by running SPR executables. To enjoy graphics, you can then load test
data and the saved classifier configuration from an interactive Root
session using loadData..() and loadClassifier() methods.


14. Summary
-----------

Feedback on the package use is very much appreciated. Send email to
the address shown on top of this file.
