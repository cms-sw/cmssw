#! /bin/bash

# load common HLT functions
if [ -f "$CMSSW_BASE/src/HLTrigger/Configuration/common/utils.sh" ]; then
  source "$CMSSW_BASE/src/HLTrigger/Configuration/common/utils.sh"
elif [ -f "$CMSSW_RELEASE_BASE/src/HLTrigger/Configuration/common/utils.sh" ]; then
  source "$CMSSW_RELEASE_BASE/src/HLTrigger/Configuration/common/utils.sh"
else
  exit 1
fi

function log() {
  echo -e "$@"
}

function err() {
  echo -e "$@" 1>&2
}


NAME=$(basename $0)

HELP="Run the integration tests over all paths in a given HLT menu.

Usage:
  $NAME -h|--help
  $NAME [-d|--dir WORKDIR] [-s|--setup SETUP] [-i|--input RAW] [-j|--jobs JOBS]
        [--streams STREAMS] [--threads THREADS] [-x|--extra OPTIONS] [--mc]
        [ [-n|--size EVENTS] [-k|--skip EVENTS] | [-e|--events EVENTS] ] MENU

  MENU is the HLT menu to test.

  -s | --setup SETUP          Use the Services and EventSetup modules from a different menu
                              (usefull when testing a ConfDB area with only some new paths).
                              Note it is an error to specify the converter/db here, 
                              it uses the same as set by the HLT menu
  -d | --dir      WORKDIR     Create all files and run all tests inside WORKDIR (defauls: ./hltintegration)
  -i | --input    INPUT       Use the specified RAW data file as input
  -n | --size     EVENTS      Run on EVENTS events (-1 for all, default is 100)
  -k | --skip     EVENTS      Skip the first EVENTS (default is 0)
  -e | --events   EVENTS      Run on a comma-separated list of EVENTS, a VEventRange
  -j | --jobs     JOBS        Run JOBS single trigger jobs in parallel (default 4)
       --streams  STREAMS     Run with STREAMS parallel streams (i.e. events) (default 0 means as many streams as threads)
       --threads  THREADS     Run with THREADS threads when running the whole HLT (default 4)
  -x | --extra    OPTIONS     Pass OPTIONS directly to hltGetConfiguration
       --mc                   Run over MC instead of data (the default)
  --dbproxy                   Use a socks proxy to connect to the HLT database
  --dbproxyhost    PROXYHOST  Host of the socks proxy (default: "localhost")
  --dbproxyport    PROXYPORT  Port of the socks proxy (default: 8080)
  -h | --help                 Print this help message and exit.


  The supported formats for both menu specifications are:
    - /path/to/configuration[/Vn]
    - [[{v1|v2|v3}/]{run3|run2|online|adg}:]/path/to/configuration[/Vn]
    - run:runnumber
  The possible converters are \"v1\", \"v2\", and \"v3\" (default).
  The possible databases are \"run3\" (default, used for offline run3 development), \"run2\" (previously used for run2 development), \"online\" (used to
  extract online menus within Point 5) and \"adg\" (used to extract the online menus outside Point 5).
  If no menu version is specified, the latest one is automatically used.
  If \"run:\" is used instead, the HLT menu used for the given run number is looked up and used.
  Note other converters and databases exist but they are for expert/special use only.

  It's possible to pass arbitrary command line options to hltGetConfiguration, using \"-x --option\".
  To pass multiple options, enclose them in quotes, or use \"-x\" more than once.

  Note: '--events' is not supported together with '--size' or '--skip'.


Exmples:

  $NAME /dev/CMSSW_4_2_0/GRun

      will test the latest version of the GRun menu.


  $NAME /dev/CMSSW_4_2_0/GRun -x --l1-emulator

      will test the latest version of the GRun, running the L1 emulator.


  $NAME /users/fwyzard/physics/HLT/V6 -s adg:/cdaq/physics/Run2011/1e33/v1.3/HLT/V6

      will test the paths from /users/fwyzard/physics/HLT/V6, using the environment from the
      online menu \"1e33\" v1.3 V6

"

# parse command line argument and options
OPTS=$(getopt -n "$NAME" -o "s:d:i:j:n:k:e:x:h" -l "setup:,dir:,input:,jobs:,size:,skip:,streams:,threads:,events:,mc,extra:,help,dbproxy,dbproxyhost:,dbproxyport:" -- "$@")

# invalid options
if [ $? != 0 ]; then
  exit 1
fi

# reload the parsed options into the environment
eval set -- "$OPTS"

# check how many CPUs are available
CPUS=`getconf _NPROCESSORS_ONLN`

MENU=""
SETUP=""
INPUT=""
SIZE=100
SKIP=0
EVENTS=""
JOBS=4
THREADS=4
STREAMS=0
WORKDIR="hltintegration"
EXTRA=""
DATA="--data"
HLTLISTPATHPROXY=""

SELECTION=""

# parse options
while true; do
  case "$1" in
    "-h" | "--help" )
      echo "$HELP"
      exit 0
      ;;
    "-s" | "--setup" )
      SETUP="$2"
      shift 2
      ;;
    "-d" | "--dir" )
      WORKDIR="$2"
      shift 2
      ;;
    "-i" | "--input" )
      INPUT="--input $2"
      shift 2
      ;;
    "-n" | "--size" )
      if [ "$SELECTION" == "complex" ]; then
        err "'--events' is not supported together with '--size' or '--skip'"
        exit 1
      fi
      SELECTION="simple"
      SIZE=$2
      if ((SIZE == 0)) && [ "$SIZE" != "0" ]; then
        err "$NAME error: invalid option \"$1 $2\""
        err "Try '$NAME --help' for more information."
        exit 1
      fi
      shift 2
      ;;
    "-k" | "--skip" )
      if [ "$SELECTION" == "complex" ]; then
        err "'--events' is not supported together with '--size' or '--skip'"
        exit 1
      fi
      SELECTION="simple"
      SKIP=$2
      if ((SKIP == 0)) && [ "$SKIP" != "0" ]; then
        err "$NAME error: invalid option \"$1 $2\""
        err "Try '$NAME --help' for more information."
        exit 1
      fi
      shift 2
      ;;
    "-e" | "--events" )
      if [ "$SELECTION" == "simple" ]; then
        err "'--events' is not supported together with '--size' or '--skip'"
        exit 1
      fi
      SELECTION="complex"
      SIZE=-1
      EVENTS="$2"
      shift 2
      ;;
    "-j" | "--jobs" )
      JOBS=$2
      if ((JOBS == 0)); then
        err "$NAME error: invalid option \"$1 $2\""
        err "Try '$NAME --help' for more information."
        exit 1
      fi
      shift 2
      ;;
    "--streams" )
      STREAMS=$2
      shift 2
      ;;
    "--threads" )
      THREADS=$2
      shift 2
      ;;
    "-x" | "--extra" )
      EXTRA="$EXTRA $2"
      shift 2
      ;;
    "--mc" )
      DATA="--mc"
      shift 1
      ;;
    "--dbproxy" )
      HLTLISTPATHPROXY="$HLTLISTPATHPROXY --dbproxy"
      EXTRA="$EXTRA --dbproxy"
      shift 1
      ;;
    "--dbproxyhost" )
      HLTLISTPATHPROXY="$HLTLISTPATHPROXY --dbproxyhost $2"
      EXTRA="$EXTRA --dbproxyhost $2"
      shift 2
      ;;
    "--dbproxyport" )
      HLTLISTPATHPROXY="$HLTLISTPATHPROXY --dbproxyport $2"
      EXTRA="$EXTRA --dbproxyport $2"
      shift 2
      ;;
    "--" )
      # inserted by getopt to singal the end of options
      shift
      break
      ;;
  esac
done

# parse required argument
if (( $# == 0 )); then
  err "$NAME error: missing argument."
  err "Try '$NAME --help' for more information."
  exit 1
elif (( $# > 1 )); then
  err "$NAME error: too many arguments."
  err "Try '$NAME --help' for more information."
  exit 1
else
  MENU="$1"
fi


# run the tests
rm -rf "$WORKDIR"
mkdir  "$WORKDIR"
cd     "$WORKDIR"

# find the list of all trigger paths
TRIGGERS=$(hltListPaths "$MENU" $HLTLISTPATHPROXY -p --no-dep --exclude "^HLTriggerFinalPath$" "^Dataset_.+")
echo "${TRIGGERS[@]}" > paths.txt

# print some info
if [ "$SELECTION" == "complex" ]; then
  log "Will run $(echo $TRIGGERS | wc -w) HLT paths over $(echo $EVENTS | tr ',' '\n' | wc -l) events, with $JOBS jobs in parallel"
elif [ "$SIZE" == "-1" ]; then
  log "Will run $(echo $TRIGGERS | wc -w) HLT paths over all events, with $JOBS jobs in parallel"
else
  log "Will run $(echo $TRIGGERS | wc -w) HLT paths over $SIZE events, with $JOBS jobs in parallel"
fi

# create all dumps
log "Extracting full menu dump"
hltGetConfiguration "$MENU" --full --offline $DATA $INPUT --unprescale --process "TEST$(date -u +'%Y%m%d%H%M%S')" --max-events $SIZE $EXTRA > hlt.py

# if missing, add a simplified HLTriggerFinalPath
if ! grep -q HLTriggerFinalPath hlt.py; then
  cat >> hlt.py << @EOF
# add (simplified) HLTriggerFinalPath if missing
process.hltTriggerSummaryAOD = cms.EDProducer( "TriggerSummaryProducerAOD",
    processName = cms.string( "@" )
)
process.hltTriggerSummaryRAW = cms.EDProducer( "TriggerSummaryProducerRAW",
    processName = cms.string( "@" )
)
process.HLTriggerFinalPath = cms.Path( process.hltTriggerSummaryAOD + process.hltTriggerSummaryRAW )

@EOF
fi

# select which events to run on
if [ "$SELECTION" == "complex" ]; then
  cat >> hlt.py << @EOF
# event selection customised by hltIntegrationTests
process.source.eventsToProcess = cms.untracked.VEventRange( '$(echo $EVENTS | sed -e"s/,/','/g")' )
@EOF
elif (( $SKIP > 0 )); then
  cat >> hlt.py << @EOF
# event selection customised by hltIntegrationTests
process.source.skipEvents = cms.untracked.uint32( $SKIP )
@EOF
fi

# set the number of threads and streams for the whole hlt job
cat >> hlt.py << @EOF
# configure multithreading, and allocate 10 MB of stack space per thread
process.options.numberOfThreads = cms.untracked.uint32( $THREADS )
process.options.numberOfStreams = cms.untracked.uint32( $STREAMS )
process.options.sizeOfStackForThreadsInKB = cms.untracked.uint32( 10*1024 )
process.options.accelerators = cms.untracked.vstring( 'cpu' )

process.hltTriggerSummaryAOD.throw = cms.bool( True )
@EOF

# dump the menu name, and its release template
log "HLT menu: $(head -n1 hlt.py | cut -c 3-)"

# check the prescale modules
hltCheckPrescaleModules -w hlt.py

# check for multi-threading
edmCheckMultithreading hlt.py | grep legacy

log "Preparing single-path configurations"
for TRIGGER in $TRIGGERS; do
  cat > "$TRIGGER".py << @EOF
from hlt import *

process.hltOutput = cms.OutputModule( "PoolOutputModule",
    fileName = cms.untracked.string( "$TRIGGER.root" ),
    fastCloning = cms.untracked.bool( False ),
    outputCommands = cms.untracked.vstring(
      'drop *',
      'keep edmTriggerResults_*_*_*',
    )
)

process.Output = cms.EndPath( process.hltOutput )

process.schedule = cms.Schedule( process.$TRIGGER, process.HLTriggerFinalPath, process.Output )

process.hltTriggerSummaryAOD.throw = cms.bool( True )
@EOF
done

# if a separate setup is requested, create the setup_cff.py file and patch all dumps to use it
if [ "$SETUP" ]; then
  log "Extracting setup_cff dump"
  #we use $MENU not $SETUP here as we force the same DB / converter as the main menu
  #this is the hltGetConfiguration behaviour and would be confusing if you had to 
  #specify converter/db on the setup menu on hltIntegration tests but not on hltGetConfiguration
  read SETUP_Vx SETUP_DB _ <<< $(parse_HLT_menu "$MENU")

  hltConfigFromDB --$SETUP_Vx --$SETUP_DB $HLTLISTPATHPROXY --cff --configName "$SETUP" --nopaths --services -FUShmDQMOutputService,-PrescaleService,-EvFDaqDirector,-FastMonitoringService > setup_cff.py
  sed -i -e's/process = cms.Process(.*)/&\nprocess.load("setup_cff")/' hlt.py $(for TRIGGER in $TRIGGERS; do echo "$TRIGGER".py; done)
fi

# run all HLT dumps
cat > .makefile << @EOF
TRIGGERS=$(echo $TRIGGERS)
CFGS=\$(TRIGGERS:%=%.py)
LOGS=\$(TRIGGERS:%=%.log)
DONE=\$(TRIGGERS:%=%.done)

.PHONY: all clean hlt \$(TRIGGERS)

all: hlt \$(TRIGGERS)

clean:
	@rm -f hlt.log hlt.done \$(LOGS) \$(DONE)

hlt: hlt.done

hlt.done: hlt.py
	@echo -e "\tfull menu dump"
	@cmsRun hlt.py >& hlt.log < /dev/zero && touch hlt.done

\$(TRIGGERS): %: %.done

\$(DONE): %.done: %.py
	@echo -e "\t\$*"
	@cmsRun \$*.py >& \$*.log < /dev/zero && touch \$*.done

@EOF

log "Running..."
# if the whole hlt job runs with multithreading, run it by itself
# otherwise, run it in parallel with the single-trigger jobs
if ((THREADS > 0)); then
  make -f .makefile hlt
  make -f .makefile -j$JOBS -k $TRIGGERS
else
  make -f .makefile -j$JOBS -k
fi


# compare HLT results
log "Comparing the results of running each path by itself with those from the full menu"
hltCompareResults
STATUS=$?
log "exit status: $STATUS"
log "done"

# done
cd ..
exit $STATUS
